{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, concatenate, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "# import pydot\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from net_utils import *\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "from keras.callbacks import EarlyStopping\n",
    "# %matplotlib inline\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Sequential\n",
    "\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSrc = \"data/\"\n",
    "imageSrc = \"data/ImageData/\"\n",
    "\n",
    "trainCSV = dataSrc + \"train_image.csv\"\n",
    "testCSV = dataSrc + \"test_image.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTRModel(csr_input_shape = (7,1), weights_path=None):    #建立CTR模型\n",
    "    \n",
    "    ConvModel = VGG19(weights='imagenet')\n",
    "    Image_INPUT = ConvModel.input\n",
    "    ConvModel = Model(inputs=Image_INPUT, outputs=ConvModel.get_layer('flatten').output)\n",
    "    \n",
    "    for layer in ConvModel.layers:\n",
    "        layer.trainable = False\n",
    "    ConvModel.layers[-3].trainable = True\n",
    "    ConvModel.layers[-4].trainable = True\n",
    "    Convnet = ConvModel.output\n",
    "#     Convnet = Dense(128, name='Convnet_fc1')(Convnet)\n",
    "#     Convnet = Activation('relu')(Convnet)\n",
    "    \n",
    "    CSR_INPUT = Input(csr_input_shape)\n",
    "    Basenet = Flatten()(CSR_INPUT)\n",
    "    Basenet = Dense(128, name='Basenet_fc1')(Basenet)\n",
    "    Basenet = Activation('relu')(Basenet)\n",
    "    \n",
    "    CTRNet = concatenate([Basenet, Convnet])\n",
    "\n",
    "    CTRNet = BatchNormalization(name = \"Bn_1\")(CTRNet)\n",
    "    \n",
    "    CTRNet = Dense(256, activation='sigmoid', name='Combnet_fc1')(CTRNet)\n",
    "\n",
    "    CTRNet = Dense(1, activation='sigmoid', name='Combnet_fc2')(CTRNet)\n",
    "    \n",
    "    if weights_path:  \n",
    "        CTRNet.load_weights(weights_path)\n",
    "        \n",
    "    CTRModel = Model(inputs = [Image_INPUT, CSR_INPUT], outputs = CTRNet, name='CTRModel')\n",
    "    \n",
    "    return CTRModel  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img_orig, X_train_csr, Y_train_orig, X_test_img_orig, X_test_csr, Y_test_orig, = load_dataset_onehot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 5000\n",
      "number of test examples = 1000\n",
      "Img_train shape: (5000, 224, 224, 3)\n",
      "CSR_train shape: (5000, 7, 1)\n",
      "Y_train shape: (5000, 1)\n",
      "Img_test shape: (1000, 224, 224, 3)\n",
      "CSR_test shape: (1000, 7, 1)\n",
      "Y_test shape: (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "print (\"number of training examples = \" + str(X_train_img_orig.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test_img_orig.shape[0]))\n",
    "print (\"Img_train shape: \" + str(X_train_img_orig.shape))\n",
    "print (\"CSR_train shape: \" + str(X_train_csr.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train_orig.transpose().shape))\n",
    "\n",
    "print (\"Img_test shape: \" + str(X_test_img_orig.shape))\n",
    "print (\"CSR_test shape: \" + str(X_test_csr.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test_orig.transpose().shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.topology.InputLayer object at 0x0000029005E45780>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000029005D45F60>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000029005E26908>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000029005E38A58>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000029000130B70>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000029005E729E8>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000029005E99748>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000029005EC4B70>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000029005EE59B0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000029005F19E48>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000029005F38E10>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000029005F81B70>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000029005FBF6D8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000029005FE0B00>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000029006001A90>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000029006034F28>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000029006044BE0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000290060F8358>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002900611DCF8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000029031274D30>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002903126B0F0>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000029008F37BE0>\n",
      "<keras.layers.core.Flatten object at 0x0000029008F0F390>\n"
     ]
    }
   ],
   "source": [
    "ctr = CTRModel( csr_input_shape = [X_train_csr.shape[1],X_train_csr.shape[2]] )\n",
    "ctr.compile(optimizer='Nadam', loss='binary_crossentropy', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E = EarlyStopping(monitor='val_loss', patience=4, verbose=0, mode='auto')\n",
    "ctr.fit([X_train_img_orig, X_train_csr], Y_train_orig.transpose(), epochs = 5, batch_size = 32, validation_split = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = imageSrc + 'True/01e5c09cgy1flam1h04p8j215j1me7gt.jpg'\n",
    "# img = image.load_img(img_path, target_size=(224, 224))\n",
    "# x = image.img_to_array(img)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# x = preprocess_input(x)\n",
    "\n",
    "# block5_pool_features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
